{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_data.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2hvLoALDmLeRkMcbNI929",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhavs10/ml-with-audio/blob/master/notebooks/session2/audio_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Audio data\n",
        "\n",
        "Hello! This quick notebook will show you how to::\n",
        "* load audio data\n",
        "* plot an audio's waveform\n",
        "* create a spectrogram\n",
        "* do quick automatic speech recognition\n",
        "\n",
        "This notebook should take about 10 minutes to run."
      ],
      "metadata": {
        "id": "66IztFTLWfRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "57rV9LgqdojT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP-iDjnJbPxM"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cdn-media.huggingface.co/speech_samples/LibriSpeech_61-70968-0000.flac"
      ],
      "metadata": {
        "id": "hptqnOvvbsZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"/content/LibriSpeech_61-70968-0000.flac\""
      ],
      "metadata": {
        "id": "HGTZy6EsbV2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell uses `Audio` from IPython` to be able to play an audio\n",
        "directly in a notebook."
      ],
      "metadata": {
        "id": "uQsXGOBlXIo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(sample)"
      ],
      "metadata": {
        "id": "VIm6XLRTcE5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Librosa](https://librosa.org/doc/latest/index.html) is a very common Python\n",
        "library for audio analysis. It allows to easily load audio files, create\n",
        "spectrograms, add effects, extract features and much more! Let's plot the\n",
        "waveform of an audio. Some quick questions to reflect about:\n",
        "\n",
        "* When is the quietest moment?"
      ],
      "metadata": {
        "id": "Kda8q6KUWw74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y, sr = librosa.load(sample)\n",
        "\n",
        "plt.plot(y);\n",
        "plt.title('Signal');\n",
        "plt.xlabel('Time (samples)');\n",
        "plt.ylabel('Amplitude');"
      ],
      "metadata": {
        "id": "ZNH3DZYPbwi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librosa also has a `waveplot` method for the same thing :)"
      ],
      "metadata": {
        "id": "popkL26jdzMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.display.waveplot(y, sr=sr);"
      ],
      "metadata": {
        "id": "LpLXq3sgdw7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we loaded a sample with librosa, we get the sample rate as well."
      ],
      "metadata": {
        "id": "CV6Uu3SfX-mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sr"
      ],
      "metadata": {
        "id": "L7yDaOeeb0Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sample rate of 22,050 means we're getting 22,050 samples in a given second.\n",
        "Let's see how many samples we have in total."
      ],
      "metadata": {
        "id": "7ETQ8A7OYCYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "id": "BBu2ADM-b51y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright! So if we get 108,156 samples, and we divide that by the\n",
        "sample rate, we should get the number of seconds in the audio. Let's see if\n",
        "that confirms our intuition."
      ],
      "metadata": {
        "id": "sX2yI-COYIph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)/sr"
      ],
      "metadata": {
        "id": "MvZZLZFGb8z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! It does!"
      ],
      "metadata": {
        "id": "8cZ87nZKYTTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright. Let's go to the next thing. What happens if we use a different sample\n",
        "rate when executing? Let's hear the audios"
      ],
      "metadata": {
        "id": "-qdA7hJuYUmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(y, rate=sr*1.5)"
      ],
      "metadata": {
        "id": "Mhsdl8KZb-Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(y, rate=sr*0.75)"
      ],
      "metadata": {
        "id": "Iu_7Llt1chYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The voice is completely distorted now! Interesting."
      ],
      "metadata": {
        "id": "RJbkHZ9CZZ6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spectrograms\n",
        "\n",
        "Cool, it's now time to build a spectrogram. We'll be using Short Time Fourier\n",
        "Transform (STFT), which means we will be using a bunch of Fourier Transforms (FT) since we have frequencies changing over time. Just as a\n",
        "reminder, FFT Is useful for decomposing a signal. STFT is useful for a signal\n",
        "that changes over time. It divides a long signal into shorter segments of equal length and applies Fourier transforms for each segment.\n",
        "\n"
      ],
      "metadata": {
        "id": "T4Z7-TtWZdYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's then build a spectrogram! Note that there are different types of \n",
        "spectrograms and many variables you can play with. Let's compute Short-Time Fourier Transform using `librosa.stft` ([spec](http://librosa.org/doc/main/generated/librosa.stft.html)) and see what we get out of it.\n"
      ],
      "metadata": {
        "id": "0CiR5SGFd_9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spec = np.abs(librosa.stft(y))\n",
        "librosa.display.specshow(spec, sr=sr, x_axis='time')\n",
        "plt.colorbar(format='%+2.0f amplitude')\n",
        "plt.title('Almost Spectrogram')"
      ],
      "metadata": {
        "id": "P6dnulFscz0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, I cannot see anything here. What is going on? The sounds we (humans) hear are concentrated in a very small frequency and amplitude ranges, so plotting the raw data is not great.\n",
        "\n",
        "![e.jpg](https://miro.medium.com/max/527/1*nRrG3uXi3jj4MHBQXBL22g.png)"
      ],
      "metadata": {
        "id": "wT14YDVwem13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we can do is to transform the y axis to be log scaled and convert the amplitude to decibels. Making the data log-based will provide us much more informative information."
      ],
      "metadata": {
        "id": "mIsX9auifGDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dec_spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
        "librosa.display.specshow(dec_spec, sr=sr, x_axis='time', y_axis='log')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Spectrogram')"
      ],
      "metadata": {
        "id": "lNkwCdJTeWM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librosa allows you to create a mel-spectrogram in two ways using the `librosa.feature.melspectrogram` method:\n",
        "* By providing the raw data, as we did before (you set the `y` param).\n",
        "* By providing a pre-computer power spectrogram (you set `S` param)."
      ],
      "metadata": {
        "id": "7KD8n9LccWOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sg = librosa.feature.melspectrogram(y, sr=sr)\n",
        "db_spec = librosa.power_to_db(sg, ref=np.max)\n",
        "librosa.display.specshow(db_spec, x_axis='time', y_axis='mel', fmax=8000)\n",
        "plt.colorbar(format='%+2.0f dB')"
      ],
      "metadata": {
        "id": "C3-3zK5HhJ7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sg = librosa.feature.melspectrogram(S=spec, sr=sr)\n",
        "db_spec = librosa.amplitude_to_db(sg, ref=1.0, amin=1e-05, top_db=80.0)\n",
        "librosa.display.specshow(db_spec, x_axis='time', y_axis='mel', fmax=8000)\n",
        "plt.colorbar(format='%+2.0f dB')"
      ],
      "metadata": {
        "id": "ptw3Qlpic2mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic Speech Recognition demo\n",
        "\n",
        "Let's very quickly show you how to do ASR with our given audio using the `transformers` library with the `pipeline`. Loading the model the first time can be a bit slow, but it's much faster afterwards."
      ],
      "metadata": {
        "id": "vAtRMqSJhxpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "KCtDBJ6mdas3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"automatic-speech-recognition\")"
      ],
      "metadata": {
        "id": "s8Y4w3mrdbyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(y)"
      ],
      "metadata": {
        "id": "q_52d2ihdkVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some useful resources worth checking if you want to re-inforce this content:\n",
        "* https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53\n",
        "* https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0\n",
        "* https://ch.mathworks.com/matlabcentral/answers/387458-why-my-spectrogram-have-negative-values"
      ],
      "metadata": {
        "id": "Qo_AMDXciIyd"
      }
    }
  ]
}