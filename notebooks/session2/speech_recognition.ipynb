{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech Recognition [Tutorial].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SpeechBrain + HuggingFace for Speech Recognition tasks\n",
        "\n",
        "compiled by: [Vaibhav Srivastav](https://twitter.com/reach_vb)\n",
        "\n",
        "for pre-reads + further materials headover to: [ml-with-audio repo](https://github.com/Vaibhavs10/ml-with-audio)"
      ],
      "metadata": {
        "id": "quYLA2D9Os79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "some important Speech Recognition tasks:\n",
        "- **Speech Recognition**: Speech-to-text ([see this tutorial](https://colab.research.google.com/drive/1aFgzrUv3udM_gNJNUoLaHIm78QHtxdIz?usp=sharing))\n",
        "- **Speaker Recognition**: Speaker verification/ID ([see this tutorial](https://colab.research.google.com/drive/1UwisnAjr8nQF3UnrkIJ4abBMAWzVwBMh?usp=sharing)).\n",
        "- **Speaker Diarization**: Detect who spoke when.\n",
        "- **Speech Enhancement**: Noisy to clean speech ([see this tutorial](https://colab.research.google.com/drive/18RyiuKupAhwWX7fh3LCatwQGU5eIS3TR?usp=sharing)).\n",
        "- **Speech Separation**: Separate overlapped speech ([see this tutorial](https://colab.research.google.com/drive/1YxsMW1KNqP1YihNUcfrjy0zUp7FhNNhN?usp=sharing)). \n",
        "- **Spoken Language Understanding**: Speech to intent/slots. \n",
        "- **Multi-microphone processing**: Combining input signals ([see this tutorial](https://colab.research.google.com/drive/1UVoYDUiIrwMpBTghQPbA6rC1mc9IBzi6?usp=sharing))."
      ],
      "metadata": {
        "id": "yWARjsRhOVU_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xKGzpdbOE_D"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install speechbrain\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speechbrain as sb\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "XFUnd8qMO5Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's use a pre-trained model from the HF hub and transcribe some text"
      ],
      "metadata": {
        "id": "AbNqC-f6PeQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.pretrained import EncoderDecoderASR\n",
        "\n",
        "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", savedir=\"pretrained_models/asr-crdnn-rnnlm-librispeech\")\n",
        "asr_model.transcribe_file('speechbrain/asr-crdnn-rnnlm-librispeech/example.wav')"
      ],
      "metadata": {
        "id": "8rdpr9hVPCTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal = read_audio(\"example.wav\").squeeze()\n",
        "Audio(signal, rate=16000)"
      ],
      "metadata": {
        "id": "E_CuLNbBPKSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your turn, find a model from [HF Hub](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads) and transcribe the wav file\n",
        "\n",
        "Try both the types of pretrained ASR models:\n",
        "\n",
        "1. EncoderDecoderASR\n",
        "2. EncoderASR"
      ],
      "metadata": {
        "id": "NKd0iKqMP_ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.pretrained import EncoderDecoderASR\n",
        "\n",
        "asr_model = EncoderDecoderASR.from_hparams(source=\"<Pretrained model goes here>\", savedir=\"pretrained_models/<Pretrained model name>\")\n",
        "asr_model.transcribe_file('speechbrain/asr-crdnn-rnnlm-librispeech/example.wav')"
      ],
      "metadata": {
        "id": "OQ25aB_nPW42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's take it up a notch: What if we are provided with a sound file with multiple speakers, how do we seperate their individual sounds?"
      ],
      "metadata": {
        "id": "ub9UrXjDRugx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.pretrained import SepformerSeparation as separator\n",
        "\n",
        "model = separator.from_hparams(source=\"speechbrain/sepformer-wsj02mix\", savedir='pretrained_models/sepformer-wsj02mix')\n",
        "est_sources = model.separate_file(path='speechbrain/sepformer-wsj02mix/test_mixture.wav') "
      ],
      "metadata": {
        "id": "Idbe73EFRr0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal = read_audio(\"test_mixture.wav\").squeeze()\n",
        "Audio(signal, rate=8000)"
      ],
      "metadata": {
        "id": "AoUd9YaaSkd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(est_sources[:, :, 0].detach().cpu().squeeze(), rate=8000)"
      ],
      "metadata": {
        "id": "fyV2TzwXSopl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(est_sources[:, :, 1].detach().cpu().squeeze(), rate=8000)"
      ],
      "metadata": {
        "id": "nTKwAilUSvNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your turn, find a model from [HF Hub](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads) and separate the sounds\n",
        "\n",
        "Look for Sepformer :)"
      ],
      "metadata": {
        "id": "Slfem2H9S91E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.pretrained import SepformerSeparation as separator\n",
        "\n",
        "model = separator.from_hparams(source=\"<Pretrained model goes here>\", savedir='pretrained_models/<Pretrained model name>')\n",
        "est_sources = model.separate_file(path='speechbrain/sepformer-wsj02mix/test_mixture.wav') "
      ],
      "metadata": {
        "id": "hyESMfysSzYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alright, so far so good, let's now try to see if we can verify if two audio files are from the same speaker"
      ],
      "metadata": {
        "id": "o_AwHq33URv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.pretrained import SpeakerRecognition\n",
        "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
        "score, prediction = verification.verify_files(\"speechbrain/spkrec-ecapa-voxceleb/example1.wav\", \"speechbrain/spkrec-ecapa-voxceleb/example2.flac\")\n",
        "\n",
        "print(prediction, score)"
      ],
      "metadata": {
        "id": "G46db0fgTofZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal = read_audio(\"example1.wav\").squeeze()\n",
        "Audio(signal, rate=16000)"
      ],
      "metadata": {
        "id": "UpGb-xI7VS48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal = read_audio(\"example2.flac\").squeeze()\n",
        "Audio(signal, rate=16000)"
      ],
      "metadata": {
        "id": "YyRRqNkkVXD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Want to have more fun with pre-trained models and out of the box tasks, head over to the [SpeechBrain documentation](https://speechbrain.readthedocs.io/en/latest/API/speechbrain.pretrained.interfaces.html)\n",
        "\n",
        "Some suggestions:\n",
        "\n",
        "- [Speech Enhancement](https://huggingface.co/speechbrain/metricgan-plus-voicebank)\n",
        "- [Command Recognition](https://huggingface.co/speechbrain/google_speech_command_xvector)\n",
        "- [Spoken Language Understanding](https://huggingface.co/speechbrain/slu-timers-and-such-direct-librispeech-asr)\n",
        "- [Urban Sound Classification](https://huggingface.co/speechbrain/urbansound8k_ecapa)\n",
        "\n",
        "Send us your experiments on twitter or discord ;)"
      ],
      "metadata": {
        "id": "zmsfDpRMVkuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's train a ASR model on some sample files!"
      ],
      "metadata": {
        "id": "1QUmFY_cWh5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/speechbrain/speechbrain.git"
      ],
      "metadata": {
        "id": "Op0aX_09VZTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd speechbrain/tests/integration/neural_networks/ASR_CTC/\n",
        "!python example_asr_ctc_experiment.py hyperparams.yaml "
      ],
      "metadata": {
        "id": "W14hnYWKX002"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd speechbrain/tests/integration/neural_networks/ASR_CTC/\n",
        "!cat example_asr_ctc_experiment.py"
      ],
      "metadata": {
        "id": "S6XAoSFPYMbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd speechbrain/tests/integration/neural_networks/ASR_CTC/\n",
        "!cat hyperparams.yaml"
      ],
      "metadata": {
        "id": "vVL9_Mg3boKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your turn, Take the sample data and train a Seq2Seq model next.\n",
        "\n",
        "Hint: Look at the [integrations folder](https://github.com/speechbrain/speechbrain/tree/develop/tests/integration/neural_networks) ;)"
      ],
      "metadata": {
        "id": "KMrC3LBBcHWt"
      }
    }
  ]
}