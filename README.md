# Hugging Face Machine Learning for Audio Study Group

Welcome to the ML for Audio Study Group. Through a series of presentations, paper reading and discussions, we'll explore the field of applying Machine Learning in the Audio domain. Some examples of this are:
* Generating synthetic sound out of a given text (think of conversational assistants)
* Transcribing audio signals to text.
* Removing noise out of an audio.
* Separating different sources of audio.
* Identifying which speaker is talking.
* And much more!

We suggest you to join the community Discord at http://hf.co/join/discord, and we're looking forward to meet at the #ml-4-audio-study-group channel.

## Organisation

We'll kick off with some basics and then collaboratively decide the further direction of the group.
Before each session: 
* Read/watch related resources
During each session, you can
* Ask question in the forum
* Present  a short (~10-15mins) presentation on the topic (agree beforehand)
Before/after:
* Keep discussing/asking questions about the topic (#ml-4-audio-study channel on discord)
* Share interesting resources

## Schedule

| Date         | Topics                                                    | Resources (To read before)                                                                                                                                                                                                           |
|--------------|-----------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Dec 14, 2021 | Kickoff + Overview of Audio related usecases| [The 3 DL Frameworks for e2e Speech Recognition that power your devices](https://heartbeat.comet.ml/the-3-deep-learning-frameworks-for-end-to-end-speech-recognition-that-power-your-devices-37b891ddc380)                         |
| Dec 21, 2021 | <ul><li> Intro to Audio </li><li>Automatic Speech Recognition Deep Dive</li></ul> | <ul><li> [Intro to Audio for FastAI Sections 1 and 2](https://nbviewer.org/github/mogwai/fastai_audio/blob/master/tutorials/01_Intro_to_Audio.ipynb) </li><li> [Speech and Language Processing 26.1-26.5](https://web.stanford.edu/~jurafsky/slp3/)</li> |
| Dec 28, 2021 | Text to Speech Deep Dive                                | TBD                                                                                                                                                                                                                                  |

## Supplementary Resources

In case you want to solidify a concept, or just want to go down further deep into the speech processing rabbit-hole.
### General Resources
* Slides from LSA352: [Slides](https://nlp.stanford.edu/courses/lsa352/) (no videos available)
* Slides from CS224S (Latest): [Slides](http://web.stanford.edu/class/cs224s/syllabus/) (no videos available)
* Speech & Language Processing Book (Chapters 25 & 26) - [E-book](https://web.stanford.edu/~jurafsky/slp3/)

### Research Papers
* Speech Recognition Papers: [Github repo](https://github.com/wenet-e2e/speech-recognition-papers)
* Speech Synthesis Papers: [Github repo](https://github.com/xcmyz/speech-synthesis-paper)

### Toolkits
* Speechbrain - [Github repo](https://speechbrain.github.io/)
* Toucan - [Github repo](https://github.com/DigitalPhonetics/IMS-Toucan)
* ESPnet - [Github repo](https://github.com/espnet/espnet)

## Demos
* https://huggingface.co/spaces/akhaliq/steerable-nafx
* https://huggingface.co/spaces/akhaliq/coqui-ai-tts
* https://huggingface.co/spaces/facebook/XLS-R-2B-22-16
* https://huggingface.co/spaces/nateraw/spotify-pedalboard-demo
As the study group progresses, we'll continue to add community demos/ scripts/ URLs here.
